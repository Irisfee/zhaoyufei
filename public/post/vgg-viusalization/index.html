<!DOCTYPE html><html lang="en-us" >

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  
  
  
  <meta name="generator" content="Wowchemy 5.0.0-beta.1 for Hugo">
  

  

  
  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Yufei Zhao">

  
  
  
    
  
  <meta name="description" content="In this notebook, I am going to show you  How to extract the features for a set of images at a certain layer of VGG16 pretrained model with PyTorch. How to use PCA(Principle component analysis) to reduce the feature dimension for better visualization.">

  
  <link rel="alternate" hreflang="en-us" href="/post/vgg-viusalization/">

  







  




  
  
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  

  
  
  
  <meta name="theme-color" content="rgb(251, 191, 183)">
  

  
  
  
  <script src="/js/mathjax-config.js"></script>
  

  
  
  
  
    
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.css" integrity="sha512-1xoFisiGdy9nvho8EgXuXvnpR5GAMSjFwp40gSRE3NwdUdIMIKuPa7bqoUhLD0O/5tPNhteAsE5XyyMi5reQVA==" crossorigin="anonymous">
    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.2.2/lazysizes.min.js" integrity="sha512-TmDwFLhg3UA4ZG0Eb4MIyT1O1Mb+Oww5kFG0uHqXsdbyZz9DcvYQhKpGgNkamAI6h2lGGZq2X8ftOJvF/XjTUg==" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    

  

  
  
  
    
      
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Cutive+Mono%7CLora:400,700%7CRoboto:400,700&display=swap">
    
  

  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.e61a13a3db7408951e9f1ca8976d48ae.css">

  





<script async src="https://www.googletagmanager.com/gtag/js?id=G-NBKV8F2XP3"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url, target) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           if (target !== '_blank') {
             document.location = url;
           }
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target, event.target.getAttribute('target'));  
  }

  gtag('js', new Date());
  gtag('config', 'G-NBKV8F2XP3', {});

  
  document.addEventListener('click', onClickCallback, false);
</script>


  

  


  
  

  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/images/icon_hu8daf07698441511167650349ca463977_8870_32x32_fill_lanczos_center_2.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_hu8daf07698441511167650349ca463977_8870_192x192_fill_lanczos_center_2.png">

  <link rel="canonical" href="/post/vgg-viusalization/">

  
  
  
  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@_zhaoyufei">
  <meta property="twitter:creator" content="@_zhaoyufei">
  
  <meta property="og:site_name" content="Yufei Zhao | 赵雨菲">
  <meta property="og:url" content="/post/vgg-viusalization/">
  <meta property="og:title" content="Visualize image set based on VGG16 Convolutional layer features | Yufei Zhao | 赵雨菲">
  <meta property="og:description" content="In this notebook, I am going to show you  How to extract the features for a set of images at a certain layer of VGG16 pretrained model with PyTorch. How to use PCA(Principle component analysis) to reduce the feature dimension for better visualization."><meta property="og:image" content="/post/vgg-viusalization/featured.png">
  <meta property="twitter:image" content="/post/vgg-viusalization/featured.png"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2020-11-16T20:21:35-08:00">
    
    <meta property="article:modified_time" content="2020-11-16T20:21:35-08:00">
  

  


    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "/post/vgg-viusalization/"
  },
  "headline": "Visualize image set based on VGG16 Convolutional layer features",
  
  "image": [
    "/post/vgg-viusalization/featured.png"
  ],
  
  "datePublished": "2020-11-16T20:21:35-08:00",
  "dateModified": "2020-11-16T20:21:35-08:00",
  
  "author": {
    "@type": "Person",
    "name": "Yufei Zhao"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Yufei Zhao | 赵雨菲",
    "logo": {
      "@type": "ImageObject",
      "url": "/images/icon_hu8daf07698441511167650349ca463977_8870_192x192_fill_lanczos_center_2.png"
    }
  },
  "description": "In this notebook, I am going to show you  How to extract the features for a set of images at a certain layer of VGG16 pretrained model with PyTorch. How to use PCA(Principle component analysis) to reduce the feature dimension for better visualization."
}
</script>

  

  


  


  





  <title>Visualize image set based on VGG16 Convolutional layer features | Yufei Zhao | 赵雨菲</title>

</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper  ">

  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.1df0392aab543464b23a85146803aaf2.js"></script>

  

<aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control">
        
      </div>

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header">
    












<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Yufei Zhao | 赵雨菲</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Yufei Zhao | 赵雨菲</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-end" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/project_landing"><span>Projects</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
        

        <li class="nav-item">
          <a class="nav-link  active" href="/post"><span>Posts</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/publication_landing"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/gallery"><span>Gallery</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

      
      
        
      

      
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      
      <li class="nav-item dropdown theme-dropdown">
        <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
          <i class="fas fa-moon" aria-hidden="true"></i>
        </a>
        <div class="dropdown-menu">
          <a href="#" class="dropdown-item js-set-theme-light">
            <span>Light</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-dark">
            <span>Dark</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-auto">
            <span>Automatic</span>
          </a>
        </div>
      </li>
      

      

    </ul>

  </div>
</nav>


  </div>

  <div class="page-body">
    <article class="article">

  












  

  
  
  
<div class="article-container pt-3">
  <h1>Visualize image set based on VGG16 Convolutional layer features</h1>

  

  
    


<div class="article-metadata">

  
  
  
  
  <span class="article-date">
    
    
    2020-11-16
  </span>
  


  

  

  
  
  
  
  
  <span class="middot-divider"></span>
  <a href="/post/vgg-viusalization/#disqus_thread"></a>
  

  
  

</div>

    














  
</div>



  <div class="article-container">

    <div class="article-style">
      <h2 id="in-this-notebook-i-am-going-to-show-you">In this notebook, I am going to show you</h2>
<ul>
<li>How to extract the features for a set of images at a certain layer of VGG16 pretrained model with <strong>PyTorch</strong>.</li>
<li>How to use <strong>PCA(Principle component analysis)</strong> to reduce the feature dimension for better visualization.</li>
<li>How to use <strong>t-SNE</strong> to visualize the image set based on their similarity of layer features (visualize the n-dimension features as 2-d distance).</li>
</ul>
<h2 id="image-set-for-example">Image set for example</h2>
<p>Here, I am using images from <a href="http://naturalscenesdataset.org" target="_blank" rel="noopener">Natural Scene Dataset</a>. The Natural Scenes Dataset (NSD) is a large-scale fMRI dataset conducted at ultra-high-field (7T) strength at the Center of Magnetic Resonance Research (CMRR) at the University of Minnesota. The dataset consists of whole-brain, high-resolution (1.8-mm isotropic, 1.6-s sampling rate) fMRI measurements of 8 healthy adult subjects while they viewed thousands of color natural scenes over the course of 30–40 scan sessions. Images used in this dataset are originally from <a href="https://cocodataset.org/#home" target="_blank" rel="noopener">Microsoft COCO</a>. I am working on semantic and memory-related exploratory analysis about this dataset.</p>
<pre><code class="language-python">from pathlib import Path
import h5py
from torchvision import models
from PIL import Image
from torchvision import transforms
import numpy as np
</code></pre>
<h3 id="read-in-the-image">Read in the image</h3>
<p>NSD images are square-cropped images from Microsoft Coco dataset</p>
<pre><code class="language-python"># import stimuli
sti_dir = Path('/projects/hulacon/shared/nsd/nsddata_stimuli/stimuli/nsd/nsd_stimuli.hdf5').as_posix()
sti = h5py.File(sti_dir,'r')
sti_array = sti['imgBrick']
</code></pre>
<h3 id="read-in-the-pretrianed-vgg16-model">Read in the pretrianed VGG16 model</h3>
<pre><code class="language-python"># import model
pretrained_model = models.vgg16(pretrained=True).features
pretrained_model.eval()
</code></pre>
<pre><code>Sequential(
  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): ReLU(inplace=True)
  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (3): ReLU(inplace=True)
  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (6): ReLU(inplace=True)
  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (8): ReLU(inplace=True)
  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (11): ReLU(inplace=True)
  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (13): ReLU(inplace=True)
  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (15): ReLU(inplace=True)
  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (18): ReLU(inplace=True)
  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (20): ReLU(inplace=True)
  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (22): ReLU(inplace=True)
  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (25): ReLU(inplace=True)
  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (27): ReLU(inplace=True)
  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (29): ReLU(inplace=True)
  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
)
</code></pre>
<p>Above we can see the convolutional layer structure of VGG. The index of each layer is labeled. I will use the pooling layer 1 as the example.</p>
<pre><code class="language-python">conv_layer = {
    'conv1': 0,
    'conv2': 2,
    'conv3': 5,
    'conv4': 7,
    'conv5': 10,
    'conv6': 12,
    'conv7': 14,
    'conv8': 17,
    'conv9': 19,
    'conv10': 21,
    'conv11': 24,
    'conv12': 26,
    'conv13': 28}

pooling_layer = {
    'pool1': 4,
    'pool2': 9,
    'pool3': 16,
    'pool4': 23,
    'pool5': 30}

selected_layer = pooling_layer['pool1']
</code></pre>
<pre><code class="language-python">selected_layer
</code></pre>
<pre><code>4
</code></pre>
<h3 id="image-preprocessing">Image preprocessing</h3>
<p>Here, we define the function that can normailize the input images.</p>
<pre><code class="language-python"># define preprocess parameters
# mini-batches of 3-channel RGB images of shape (3 x H x W)
preprocess = transforms.Compose([
    transforms.Resize(224),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

def image_preprocess(img):
    &quot;&quot;&quot;
    Preprocess the image and create the tensor
    &quot;&quot;&quot;
    im = Image.fromarray(img)
    input_tensor = preprocess(im) # create tensor
    input_batch = input_tensor.unsqueeze(0)# create a mini-batch as expected by the model
    return input_batch
</code></pre>
<h3 id="feature-extraction">Feature extraction</h3>
<p>Here, we define the function that can extract features at a centain layer</p>
<pre><code class="language-python">def feature_extract(tensor, selected_layer):
    for index,layer in enumerate(pretrained_model):
#         print(index, layer)
        tensor = layer(tensor)
        if (index == selected_layer):
            return tensor
</code></pre>
<h3 id="read-in-and-preprocess-pictures">Read in and preprocess pictures</h3>
<p>We are going to use 200 pictures from the stimuli set as an example. We flatten all the feature for each image in order to calculate distance between image features/ use t-SNE</p>
<pre><code class="language-python">features = []
pic_number = 200
for iImage in range(pic_number):
    img = sti_array[iImage,:,:,:]
    input_batch = image_preprocess(img)
    current_features = np.squeeze(feature_extract(input_batch, selected_layer).data.numpy())
#     print(current_features.shape)
    features.append(np.concatenate(current_features, axis=None))

</code></pre>
<pre><code class="language-python">features = np.array(features)
features.shape
</code></pre>
<pre><code>(200, 802816)
</code></pre>
<p>Since we are using the pooling layer, the feature numbers aren&rsquo;t crazily large. We can skip the following steps for PCA.
If you are extracting features from convolutional layers, PCA would be very helpful.</p>
<pre><code class="language-python"># from sklearn.decomposition import PCA

# 
# pca = PCA(n_components=1000)
# pca.fit(features)
</code></pre>
<pre><code class="language-python"># pca_features = pca.transform(features)
</code></pre>
<h3 id="t-sne-visualization">t-SNE visualization</h3>
<p>Here, we are just using some default hyperparameters for t-SNE for a simple visualization. You can try to tune the hyperparameters if you like.</p>
<pre><code class="language-python">from sklearn.manifold import TSNE
images = sti_array[0:pic_number,:,:,:]
features = np.array(features)
tsne = TSNE(n_components=2, learning_rate=150, perplexity=30, angle=0.2, verbose=2).fit_transform(features)
tx, ty = tsne[:,0], tsne[:,1]
tx = (tx-np.min(tx)) / (np.max(tx) - np.min(tx))
ty = (ty-np.min(ty)) / (np.max(ty) - np.min(ty))
</code></pre>
<pre><code>[t-SNE] Computing 91 nearest neighbors...
[t-SNE] Indexed 200 samples in 4.441s...
[t-SNE] Computed neighbors for 200 samples in 45.717s...
[t-SNE] Computed conditional probabilities for sample 200 / 200
[t-SNE] Mean sigma: 321.907110
[t-SNE] Computed conditional probabilities in 0.021s
[t-SNE] Iteration 50: error = 110.1199646, gradient norm = 0.3914785 (50 iterations in 0.065s)
[t-SNE] Iteration 100: error = 119.6677475, gradient norm = 0.2513522 (50 iterations in 0.065s)
[t-SNE] Iteration 150: error = 120.5060120, gradient norm = 0.2420261 (50 iterations in 0.063s)
[t-SNE] Iteration 200: error = 117.5590820, gradient norm = 0.4199304 (50 iterations in 0.063s)
[t-SNE] Iteration 250: error = 122.9965286, gradient norm = 0.2279717 (50 iterations in 0.060s)
[t-SNE] KL divergence after 250 iterations with early exaggeration: 122.996529
[t-SNE] Iteration 300: error = 2.4189911, gradient norm = 0.0285375 (50 iterations in 0.060s)
[t-SNE] Iteration 350: error = 1.8055801, gradient norm = 0.0019180 (50 iterations in 0.062s)
[t-SNE] Iteration 400: error = 1.6958097, gradient norm = 0.0008569 (50 iterations in 0.062s)
[t-SNE] Iteration 450: error = 1.6566454, gradient norm = 0.0006347 (50 iterations in 0.061s)
[t-SNE] Iteration 500: error = 1.6307240, gradient norm = 0.0004043 (50 iterations in 0.061s)
[t-SNE] Iteration 550: error = 1.6122439, gradient norm = 0.0003583 (50 iterations in 0.060s)
[t-SNE] Iteration 600: error = 1.5946932, gradient norm = 0.0002276 (50 iterations in 0.059s)
[t-SNE] Iteration 650: error = 1.5851456, gradient norm = 0.0002688 (50 iterations in 0.057s)
[t-SNE] Iteration 700: error = 1.5735952, gradient norm = 0.0011064 (50 iterations in 0.057s)
[t-SNE] Iteration 750: error = 1.5616177, gradient norm = 0.0003782 (50 iterations in 0.057s)
[t-SNE] Iteration 800: error = 1.5549071, gradient norm = 0.0001757 (50 iterations in 0.058s)
[t-SNE] Iteration 850: error = 1.5460689, gradient norm = 0.0002423 (50 iterations in 0.057s)
[t-SNE] Iteration 900: error = 1.5415170, gradient norm = 0.0001737 (50 iterations in 0.057s)
[t-SNE] Iteration 950: error = 1.5383173, gradient norm = 0.0000928 (50 iterations in 0.057s)
[t-SNE] Iteration 1000: error = 1.5367311, gradient norm = 0.0000665 (50 iterations in 0.059s)
[t-SNE] KL divergence after 1000 iterations: 1.536731
</code></pre>
<pre><code class="language-python">from matplotlib.pyplot import imshow
import matplotlib
width = 4000
height = 3000
max_dim = 100

full_image = Image.new('RGBA', (width, height))
for img, x, y in zip(images, tx, ty):
    tile = Image.fromarray(img)
    rs = max(1, tile.width/max_dim, tile.height/max_dim)
    tile = tile.resize((int(tile.width/rs), int(tile.height/rs)), Image.ANTIALIAS)
    full_image.paste(tile, (int((width-max_dim)*x), int((height-max_dim)*y)), mask=tile.convert('RGBA'))

matplotlib.pyplot.figure(figsize = (16,12))
imshow(full_image)
</code></pre>
<pre><code>&lt;matplotlib.image.AxesImage at 0x2aab23e3dcf8&gt;
</code></pre>
<p><img src="./Conv_extract_22_1.png" alt="png"></p>
<p>You can see clear color and shape clusters in the visualization. This makes sense since the pooling layer 1 is at a very early stage, which caputres relatively low level features of the images.</p>
<p>In below, the visulation based on pooling layer 5 is presented.
You can clearly see some semantic category clusters, like bears and bananas.</p>
<pre><code class="language-python">Image(filename='samples/pool5_600pics_try2.png') 
</code></pre>
<p><img src="./Conv_extract_25_0.png" alt="png"></p>
<h3 id="reference">Reference</h3>
<ol>
<li><a href="https://github.com/utkuozbulak/pytorch-cnn-visualizations">https://github.com/utkuozbulak/pytorch-cnn-visualizations</a></li>
<li><a href="https://nextjournal.com/ml4a/image-t-sne">https://nextjournal.com/ml4a/image-t-sne</a></li>
</ol>

    </div>

    






<div class="article-tags">
  
  <a class="badge badge-light" href="/tag/python/">Python</a>
  
  <a class="badge badge-light" href="/tag/neural-network/">Neural network</a>
  
</div>



<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=/post/vgg-viusalization/&amp;text=Visualize%20image%20set%20based%20on%20VGG16%20Convolutional%20layer%20features" target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=/post/vgg-viusalization/&amp;t=Visualize%20image%20set%20based%20on%20VGG16%20Convolutional%20layer%20features" target="_blank" rel="noopener" class="share-btn-facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=Visualize%20image%20set%20based%20on%20VGG16%20Convolutional%20layer%20features&amp;body=/post/vgg-viusalization/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=/post/vgg-viusalization/&amp;title=Visualize%20image%20set%20based%20on%20VGG16%20Convolutional%20layer%20features" target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="whatsapp://send?text=Visualize%20image%20set%20based%20on%20VGG16%20Convolutional%20layer%20features%20/post/vgg-viusalization/" target="_blank" rel="noopener" class="share-btn-whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=/post/vgg-viusalization/&amp;title=Visualize%20image%20set%20based%20on%20VGG16%20Convolutional%20layer%20features" target="_blank" rel="noopener" class="share-btn-weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>











  
  



  
  
  
    
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <img class="avatar mr-3 avatar-square" src="/author/yufei-zhao/avatar_hub2d2ba509bb5e359b836d762ea32b046_94711_270x270_fill_q75_lanczos_center.jpg" alt="Yufei Zhao">
    

    <div class="media-body">
      <h5 class="card-title">Yufei Zhao</h5>
      <h6 class="card-subtitle">PhD Candidate</h6>
      
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
    <li>
      <a href="mailto:yzhao17@uoregon.edu" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://twitter.com/_zhaoyufei" target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/irisfee" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.linkedin.com/in/yufei-zhao-4abb40ab" target="_blank" rel="noopener">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>









<section id="comments">
  
    
<div id="disqus_thread"></div>
<script>
  var disqus_config = function () {
    
    
    
  };
  (function() {
    if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
      document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
      return;
    }
    var d = document, s = d.createElement('script'); s.async = true;
    s.src = 'https://' + "zhaoyufei" + '.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


  
</section>








  
  
  <div class="article-widget content-widget-hr">
    <h3>Related</h3>
    <ul>
      
      <li><a href="/project/hitsong/">Building API for Predicting Mando-pop Popularity</a></li>
      
      <li><a href="/post/ref-data-science/">Books/video courses recommendation for data science related coding/machine learning/stats</a></li>
      
      <li><a href="/project/nsd/">Decoding memory content from human parietal cortex: VGG16 application on memory research</a></li>
      
      <li><a href="/post/mlops2/">Notes for Machine Learning Data Lifecycle in Production (MLOps2) on Coursera/Deeplearning.ai</a></li>
      
      <li><a href="/post/mlops1/">Notes for Introduction to Machine Learning in Production (MLOps1) on Coursera/Deeplearning.ai</a></li>
      
    </ul>
  </div>
  





  </div>
</article>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  

  <p class="powered-by">
    Yufei Zhao ©2021 &middot; 
    Code with ❤️ and 🍵. Powered by R <a href="https://bookdown.org/yihui/blogdown/" target="_blank" rel="noopener">Blogdown</a> and the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>
    </div>
    
  </div>

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>

      
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      

      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js" integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js" integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/latex.min.js"></script>
        
      

    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.js" integrity="sha512-SeiQaaDh73yrb56sTW/RgVdi/mMqNeM2oBwubFHagc5BkixSpP1fvqF47mKzPGWYSSy4RwbBunrJBQ4Co8fRWA==" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    
    
    
    
    <script>
      const search_config = {"indexURI":"/index.json","minLength":1,"threshold":0.3};
      const i18n = {"no_results":"No results found","placeholder":"Search...","results":"results found"};
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'event' : "Events",
        'slides' : "Slides"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    
    

    
    

    
    
    <script id="dsq-count-scr" src="https://zhaoyufei.disqus.com/count.js" async></script>
    

    
    
    
    
    
    
    
    
    
    
      
      
    
    
    <script src="/js/wowchemy.min.572b7caf7fe601716a0f74d67d754c21.js"></script>

    






</body>
</html>
