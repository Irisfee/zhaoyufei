[{"authors":null,"categories":null,"content":"I am a PhD candidate in Cognitive Neuroscience at University of Oregon. My research work is focused on using human fMRI to explain the cognitive mechanism underlying human episodic memory and using machine learning techniques to predict human memory behavior.\n","date":1554595200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1554595200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a PhD candidate in Cognitive Neuroscience at University of Oregon. My research work is focused on using human fMRI to explain the cognitive mechanism underlying human episodic memory and using machine learning techniques to predict human memory behavior.","tags":null,"title":"Yufei Zhao","type":"authors"},{"authors":null,"categories":null,"content":"Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026quot;Courses\u0026quot; url = \u0026quot;courses/\u0026quot; weight = 50  Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026quot;Docs\u0026quot; url = \u0026quot;docs/\u0026quot; weight = 50  Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Wowchemy\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Yufei Zhao"],"categories":[],"content":"Desciption is coming soon! You can check out the two github repo now!\n","date":1629615652,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629615652,"objectID":"7719df388de48bc0347d9027422bceb6","permalink":"/project/hitsong/","publishdate":"2021-08-22T00:00:52-07:00","relpermalink":"/project/hitsong/","section":"project","summary":"Desciption is coming soon! You can check out the two github repo now!","tags":["Big data","Python","Neural network","Machine learning"],"title":"Building API for Predicting Mando-pop Popularity","type":"project"},{"authors":[],"categories":[],"content":"Week1 Introduction to Machine Learning Engineering in Production Managing the entire life cycle of data  Labeling Feature space coverage Minimal dimensionality Maximum predictive data Fairness Rare conditions  Modern software development Accounts for:\n Scalability Extensibility Configureation Consistency \u0026amp; reproducibility Safety \u0026amp; security Modularity Testability Monitoring Best practice  Production machine learning system Challenges in production grade ML  Build integrated ML systems Continuously operate it in production Handle continuously changing data Optimize compute resource costs  Production ML infrastructure Directed acyclic graphs  A directed acyclic graph (DAG) is a directed graph that has no cycles ML pipeline workflows are usually DAGs. DAGs define the sequencing of the tasks to be performed, based on their relationships and dependencies.  Pipeline orchestration frameworks  Responsible for scheduling the various components in an ML pipeline DAG dependencies Help with pipeline automation Examples: Airflow, Argo, Celery, Luigi, Kubeflow  TensorFlow Extended (TFX) End-to-end platform for deploying production ML pipelines.\nSequence of components that are designed for scalable, high-performance machine learning tasks.\nTFX production components TFX Hello World Key points  Production ML pipelines: automating, monitoring, and maintaining end-to-end processes Production ML is much more than just ML code  ML development + software development   TFX is an open-source end-to-end ML platform  Collecting Data ML: Data is a first class citizen   Software 1.0\n Explicit instructions to the computer    Software 2.0\n Specify some goal on the behavior of a program Find solution using optimization techniques Good data is key for success Code in Software = Data in ML    Everything starts with data  Models aren\u0026rsquo;t magic Meaningful data:  maximize predictive content remove non-informative data feature space coverage    Data pipeline Data collection and monitoring Key points  Understand users, translate user needs into data problems Ensure data coverage and high predictive signal Source, store and monitor quality data responsibly  Example application: suggesting runs Key considerations  Data availability and collection  What kind of /how much data is available? how often does the new data come in? Is it annotated?  If not, how hard/expensive is it to get it labeled?     Translate user needs into data needs  Data needed Features needed Labels needed    Example dataset Get to know your data  Identify data sources check if they are refreshed Consistency for values, units, and types Monitor outliers and errors  Dataset issues  Inconsistent formatting  Is zero \u0026lsquo;\u0026lsquo;0\u0026quot;, \u0026ldquo;0.0\u0026rdquo;, or an indicator of a missing measurement   Compounding errors from other ML models Monitor data sources for system issues and outages  Measure data effectiveness  Intuition about data value can misleading  Which features have predictive value and which ones do not?   Feature engineering helps to maximize the predictive signals Feature selection helps to measure the predictive signals  Translate user needs into data needs Key points  Understand your user, translate their needs into data problems  What kind of / how much data is available What are the details and issues of your data What are your predictive features What are the labels you are tracking What are your metrics    Avoiding problematic biases in datasets Source data responsibly Data security and privacy  Data collection and management isn\u0026rsquo;t just about your model  Give user control of what data can be collected Is there a risk of inadvertently revealing user data?   Compliance with regulations and policies (e.g. GDPR)  Users privacy  Protect personally identifiable information  Aggregation - replace unique values with summary value Redaction - remove some data to create less complete picture    How ML systems can fail users  Representational Harm Opportunity denial Disproportionate product failure Harm by disadvantage  Commit to fairness  Make sure your models are fair  Group fairness, equal accuracy   Bias in human labeled and/or collected data ML models can amplify biases  Reducing bias: design fair labeling systems  Accurate labels are necessary for supervised learning Labeling can be done by:  Automation (logging or weak supervision) Humans (aka \u0026ldquo;raters\u0026rdquo;, often semi-supervised)    Types of human raters Key points  Ensure raters pool diversity Investigate rater context and incentives Evaluate rater tools Manage cost Determine freshness requirements  Labeling Data Case study: taking action  How to detect problems early on? What are the possible causes? What can be done to solve these?  What causes problesm? kinds of problems:\n Slow: drift Fast: bad sensor, bad software update  Gradual problems Sudden problems Why \u0026ldquo;understand\u0026rdquo; the model?  Mispredictions do not have uniform cost to your business The data you have is rarely the data you wish you had Model objective is nearly always a proxy for your business objectives Some percentage of your customers may have a bad experience  Detecting problems with deployed models  Data and scope changes Monitor models and validate data to find problems early Changing ground truth: label new training data  Easy problems  Ground truth changes slowly (months, years) Model retraining driven by:  Model improvements, better data Changes in software and/or systems   Labeling  Curated datasets Crowed-based    Harder problems  Ground truth changes faster (weeks) Model retraining driven by:  Declining model performance Model improvements, better data Changes in software and/or system   Labeling  Direct feedback Crowd-based    Really hard problems  Ground truth changes very fast (days, hours, min) Model retraining driven by:  Declining model performance Model improvements, better data Changes in software and/or system   Labeling  Direct feedback Weak supervision    Key points  Model performance decays over time  Data and concept drift   Model retraining helps to improve performance  Data labeling for changing ground truth and scarce labels    Data labeling Variety of Methods\n Process Feedback (Direct labeling) Human labeling Semi-supervised labeling Active learning Weak supervision  Why is labeling important in production ML?  using business/organization available data Frequent model retraining Labeling ongoing and critical process Creating a training datasets requires labels  Direct labeling: continuous creation of training dataset Process feedback - advantages  Training dataset continuous creation Labels evolve quickly Captures strong label signals  Process feedback -disadantages  Hindered by inherent nature of the problem Failure to capture ground truth Largely bespoke design  Process feedback- Open-source log analysis tools Logstash: free and open source data processing pipeline\n Ingests data from a multitude of sources Transforms it Sends it to your favorite \u0026ldquo;stash\u0026rdquo;  Fluentd\n Open source data collector Unify the data collection and consumption  Process feedback-Cloud log analytics Human labeling People (\u0026lsquo;raters\u0026rsquo;) to examine data and assign labels manually\nMethodology:\n Unlabeled data is collected Human (\u0026lsquo;raters\u0026rsquo;) are recruited Instructions to guide raters are created Data is divided and assigned to raters Labels are collected and conflicts resolved  Human labeling - advantages  More labels Pure supervised learning  Human labeling - disadvantages  Quality consistency: many datasets difficult for human labeling Slow Expensive Small dataset curation  Validating Data Drift and skew Drift: changes in data over time, such as data collected once a day\nSkew: Difference between two static versions, or different sources, such as training set and serving set\nTypical ML pipeline Model decay: data drift Performance decay: concept drift Detecting data issues  Detecting schema skew  Training and serving data do not conform to be the same schema   Detecting distribution skew  Dataset shift → covariate or concept shift   Requires continuous evaluation  Detecting distribution skew Skew detection workflow TensorFlow Data Validation (TFDV)  Understand, validate, and monitor ML data at scale Used to analyze and validate petabytes of data at google every day Proven track record in helping TFX users maintain the health of their ML pipelines  TFDV capabilities  Generates data statistics and browser visualizations Infers the data schema Performs validity checks against schema Detects training/serving skew  Skew detection - TFDV Skew -TFDV   Supported for categorical features\n  Expressed in terms of L-infinity distance (Chebyshev Distance):\n  Set a threshold to receive warnings\n  Schema skew Serving and training data don\u0026rsquo;t conform to same schema: int ≠ float\nFeature skew Training feature values are different than the serving feature values:\n Feature values are modified between training and serving time Transformation applied only in one of the two instances  Distribution skew Distribution of serving and training dataset is significantly different:\n Faulty sampling method during training Different data sources for training and serving data Trend, seasonality, changes in data over time  Key points  TFDV: descriptive statistics at scale with the embedded facets visualizations It provides insight into:  What are the underlying statistics of your data How does your training, evaluation, and serving dataset statistics compare How can you detect and fix data anomalies    Readings: MLops\nData 1st class citizen\nRunners app\nRules of ML\nBias in datasets\nLogstash\nFluentd\nGoogle Cloud Logging\nAWS ElasticSearch\nAzure Monitor\nTFDV\nChebyshev distance\nPapers\nKonstantinos, Katsiapis, Karmarkar, A., Altay, A., Zaks, A., Polyzotis, N., … Li, Z. (2020). Towards ML Engineering: A brief history of TensorFlow Extended (TFX). http://arxiv.org/abs/2010.02013\nPaleyes, A., Urma, R.-G., \u0026amp; Lawrence, N. D. (2020). Challenges in deploying machine learning: A survey of case studies. http://arxiv.org/abs/2011.09926\nML code fraction:\nSculley, D., Holt, G., Golovin, D., Davydov, E., \u0026amp; Phillips, T. (n.d.). Hidden technical debt in machine learning systems. Retrieved April 28, 2021, from Nips.cc https://papers.nips.cc/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf\nWeek 2 Feature Engineering Squeezing the most out of data  Making data useful before training a model Representing data in forms that help models learn Increasing predictive quality Reducing dimensionality with feature engineering  Art of feature engineering Typical ML pipeline Key points  Feature engineering can be difficult and time consuming, but also very important to success Squeezing the most out of data through feature engineering enables models to learn better Concentrating predictive information in fewer features enables more efficient use of compute resources Feature engineering during training must also be applied correctly during serving  Main preprocessing operations Mapping raw data into features Mapping categorical values Categorical vocabulary Empirical knowledge of data  Text: stemming, lemmatization, TF-IDF, n-grams, embedding lookup Images: clipping, resizing, cropping, blur, canny filters, Sobel filter, photometric distortions  Key points  Data preprocessing: transforms raw data into a clean and training-ready dataset Feature engineering maps:  Raw data into feature vectors Integer values to floating-point values Normalizes numerical values Strings and categorical values to vectors of numeric values Data from one space into a different space    Feature engineering techniques  Numerical range: scaling, normalizing, standardizing Grouping: bucketizing, bag of words  Scaling  Converts values from their natural range into a prescribed range  E.g. grayscale image pixel intensity scale is [0,255] usually rescaled to [-1,1]   Benefits  Helps neural nets converge faster Do away with NaN errors during training For each feature, the model learns the right weights    Normalization If you know the data is not gaussian usually good to do.\nStandardization (z-score) if your data is normal distribution; try both standardization and normalization.\n Z-score relates the number of standard deviations away from the mean e.g.  Bucketizing/Binning Binning with facets Other techniques  Dimensionality reduction in embeddings  PCA: principal component analysis t-SNE: t-Distributed stochastic neighbor embedding (t-SNE) UMAP: uniform manifold approximation and projection   Feature crossing  TensorFlow embedding projector  Intuitive exploration of high-dimensional data Visualize and analyze Techniques: PCA,t-SNE, UMAP, custom linear projections  Key points  Feature engineering:  Prepares, tunes, transforms, extracts, and constructs features.   Feature engineering is key for model refinement Feature engineering helps with ML analysis  Feature crosses  Combines multiple features together into a new feature Encodes nonlinearity in the feature space, or encodes the same information in fewer features Create many different kinds of feature crosses  [A*B]: multiplying the values of two features [ABCDE]: multiplying the values of 5 features [Day of week, hour]⇒[Hour of week]    Encoding features can\u0026rsquo;t be separated by a line\nFeature Transformation at Scale Preprocessing data at scale  Real-world models: terabytes of data Large-scale data processing frameworks Consistent transforms between training and serving  Inconsistencies in feature engineering  Training and serving code paths are different Diverse deployments scenarios  Mobile (TF lite) Server (TF serving) Web (TF JS)   Risks of introducing training-serving skews Skews will lower the performance of your serving model  Preprocessing granularity When do you transform? How about \u0026lsquo;within\u0026rsquo; a model? Why transform per batch?  For example, normalizing features by their average Access to a single batch of data, not the full dataset Ways to normalize per batch  Normalize by average within a batch Precompute average and reuse it during normalization    Optimizing instance-level transformations  Indirectly affect training efficiency Typically accelerators sit idle while the CPUs transform Solution: prefetching transforms for better accelerator efficiency  Summarizing the challenges  Balancing predictive performance Full-pass transformations on training data Optimizing instance-level transformations for better training efficiency (GPUs, TPUs,\u0026hellip;)  Enter tf.Transform Inside TF Extended rf.Transform layout tf.Transform: going deeper rf.Transform Analyzers How transform applies feature transformations Benefits of using tf.Transform  Emitted tf.Graph holds all necessary constants and transformations Focus on data preprocessing only at training time Works in-line during both training and serving No need for preprocessing code at serving time Consistently applied transformations irrespective of deployment platform  Analyzers framework tf.Transform preprocessing_fn Commonly used imports Hello world with tf.Transform Collect raw samples (data) Inspect data and prepare metadata (data) Preprocessing data (transform) Tensors in\u0026hellip;tensors out Running the pipeline Feature Selection Feature space  N dimensional space defined by your N features Not including the target label  Feature space coverage  Train/eval datasets representative of the serving dataset  same numerical ranges same classes similar characteristics for image data similar vocabulary, syntax, and semantics for NLP problems    Ensure feature space voerage  Data affected by: seasonality, trend, drift Serving data: new values in features and labels Continuous monitoring  Feature selection  Identify features that best represent the relationship Remove features that don\u0026rsquo;t influence the outcome Reduce the size of the feature space Reduce the resource requirements and model complexity  Why is feature selection needed?  Reduce storage and I/O requirements Minimize training and inference costs  Feature selection methods  Unsupervised  Features-target variable relationship not considered Removes redundant features (correlation)   Supervised  Uses features-target variable relationsihp Selects those contributing the most Filter methods/Wrapper Methods/Embedded Methods    Filter methods   Correlation\n  Univariate feature selection (for efficiency)\n  Popular filter methods\n Pearson correlation: between features, and between the features and the label Univariate feature selection    Correlation matrix  Shows how features are related  To each other (bad) And with target variable (good)   Falls in the range [-1, 1]  Feature comparison statistical tests  Pearson\u0026rsquo;s correlation: linear relationships Kendall Tau Rank correlation coefficient: monotonic relationships and small sample size Spearman\u0026rsquo;s Rank Correlation Coefficient: monotonic relationships Mutual information/F-test/Chi-squared test  Determine correlation Selecting features Performance table Univariate feature selection in sklearn Wrapper methods  Forward elimination backward elimination recursive feature elimination  Forward selection  Iterative, greedy method Starts with 1 feature Evaluate model performance when adding each of the additional features, one at a time Add next feature that gives the best performance Repeat until there is no improvement  Backward selection  Start with all features Evaluate model performance when removing each of the included features, one at a time Remove next feature that gives the best performance Repeat until there is no improvement  Recursive feature elimination (RFE)  Select a model to use for evaluating feature importance Select the desired number of features Fit the model Rank features by importance Discard least important features Repeat until the desired number of features remains  Embedded methods  L1 regularization Feature importance  Feature importance  Assigns scores for each feature in data Discard features scored lower by feature importance  Readings Mapping raw data into feature\nFeature engineering techniques\nScaling\nFacets\nEmbedding projector\nEncoding features\nTFX:\n https://www.tensorflow.org/tfx/guide#tfx_pipelines https://ai.googleblog.com/2017/02/preprocessing-for-machine-learning-with.html  Breast Cancer Dataset\nWeek 3 Data Journey and Data Storage The data journey  Raw features and labels Input-output map ML model to learn mapping  Data transformation  Data transforms as it flows through the process Interpreting model results requires understanding data transformation  Artifacts and the ML pipeline  Artifacts are created as the components of the ML pipeline execute Artifacts include all of the data and objects which are produced by the pipeline components This includes the data, in different stages of transformation, the schema, the model itself, metrics, etc.  Data provenance and lineage  The chain of transformations that led to the creation of a particular artifact Important for debugging and reproducibility  Data provenance: why it matters  Helps with debugging and understanding the ML pipeline:  Inspect artifacts at each point in the training process Trace back through a training run Compare training runs    Data lineage: data protection regulation  Organizations must closely track and organize personal dta Data lineage is extremely important for regulatory compliance  Data provenance: interpreting results  Data transformations sequence leading to predictions Understanding the model as it evolves through runs  Data versioning  Data pipeline management is a major challenge machine learning requires reproducibility Code versioning: github\u0026hellip; Environment versioning: docker, terraform, and similar Data versioning:  Version control of datasets examples: DVC, Git-LFS    Metadata: tracking artifacts and pipeline changes Metadata: TFX component architecture  Driver: supplies required metadata to executor Executor: place to code the functionality of component Publisher: stores result into metadata  ML metadata library  Tracks metadata flowing between components in pipeline Supports multiple storage backends  ML metadata terminology Metadata stored Inside metadatastore Other benefits of ML Metadata  Produce DAG of pipelines Verify the inputs used in a nexecution List all artifacts Compare artifacts  ML Metadata storage backend  ML metadata registers metadata in a database called metadata store APIs to record and retrieve metadata to and from the storage backend:  Fake database: in-memory for fast experimentation/prototyping SQLite: in-memory and disk MySQL: server based Block storage: file system, storage area network, or cloud based    Evolving Data Recall schema Iterative schema development and evolution Reliability during data evolution Platform needs to be resilient to disruptions from:\n Inconsistent data Software User configurations Execution environments  Scalability during data evolution Platform must scale during:\n High data volume during training Variable request traffic during serving  Anomaly detection during data evolution Platform designed with these principles:\n easy to detect anomalies data errors treated same as code bugs Updata data schema  Schema inspection during data evolution  Looking at schema versions to track data evolution Schema can drive other automated processes  Multiple schema versions Maintaining varieties of schema  business use-case needs to support data from different sources Data evolves rapidly Is anomaly part of accepted type of data  Schema environments  Customize the schema for each environment Ex: add or remove label in schema based on type of dataset  Enterprise Data Storage Feature stores Many modeling problems use identical or similar features\n avoid duplication control access purge  Offline feature processing Online feature usage  Low latency access to features Features difficult to compute online Precompute and store for low latency access  Features for online serving: batch Batch precomputing and loading history\n Simple and efficient Works well for features to only be updated every few hours or once a day Same data is used for training and serving  Feature store: key aspects  managing feature data from a single person to large enterprises Scalable and performant access to feature data in training and servign Provide consistent and point-in-time correct access to feature data Enable discovery, documentation, and insights into your features  Data warehouse  Aggregates data sources Processed and analyzed read optimized Not real time Follows schema  Key features of data warehouse  Subject oriented Integrated Non volatile time variant  Advantages of data warehouse  Enhanced ability to analyze data Timely access to data Enhanced data quality and consistency High return on investment Increased query and system performance  Comparison with databases Data lakes  Aggregates raw data from one or more sources Data can be structured or unstructured Doesn\u0026rsquo;t involve any processing before writing data  Comparison with data warehouse Key points  Feature store: central repository for storing documented, curated, and access-controlled features, specifically for ML Data warehouse: subject-oriented repository of structured data optimized for fast read Data Lakes: repository of data stored in its natural and raw format  Reading If you wish to dive more deeply into the topics covered this week, feel free to check out these optional references. You won’t have to read these to complete this week’s practice quizzes.\nData Versioning:\n https://dvc.org/ https://git-lfs.github.com/  ML Metadata:\n https://www.tensorflow.org/tfx/guide/mlmd#data_model https://www.tensorflow.org/tfx/guide/understanding_custom_components  Chicago taxi trips data set:\n https://data.cityofchicago.org/Transportation/Taxi-Trips/wrvz-psew/data https://archive.ics.uci.edu/ml/datasets/covertype  Feast:\n https://cloud.google.com/blog/products/ai-machine-learning/introducing-feast-an-open-source-feature-store-for-machine-learning https://github.com/feast-dev/feast https://blog.gojekengineering.com/feast-bridging-ml-models-and-data-efd06b7d1644  Week 4 Advanced Labeling Why is advanced labeling important  manually labeling of data is expensive Unlabeled data is usually cheap and easy to get Unlabeled data contains a lot of information that can improve our model  Semi-supervised learning  Advantages  Combining labeled and unlabeled data boosts accuracy Getting unlabeled data is cheap    Label propagation  Semi-supervised ML algorithm A subset of the examples have labels Labels are propagated to the unlabeled points:  Based on similarity of \u0026ldquo;community structure\u0026rdquo;    Label propagation - graph based  Unlabeled examples can be assigned labels based on their neighbors  Active learning  A family of algorithms for intelligently sampling data Select the points to be labeled that would be most informative for model training Very helpful in the following situations:  Constrained data budgets: you can only afford labeling a few points Imbalanced dataset: helps selecting rare classes for training Target metrics: when baseline sampling strategy does not improve selected metrics    Active learning strategies Active learning cycle Margin sampling repeat until the performance doesn\u0026rsquo;t improve\nActive learning sampling techniques  Margin sampling: label points the current model is least confident in Cluster-based sampling: sample from well-formed clusters to \u0026lsquo;cover\u0026rsquo; the entire space Query-by-committee: train an ensemble of models and sample points that generate disagreement Region-based sampling: runs several active learning algorithms in different partitions of the space  Weak supervision Weak supervision is about leveraging higher-level and/or noisier input from subject matter experts.\n Unlabeled data, without ground-truth labels One or more weak supervision sources  a list of heuristics that can automate labeling Typically provided by subject matter experts   Noisy labels have a certain probability of being correct, not 100% Objective: learn a generative model to determine weights for weak supervision sources  Snorkel  Programmatically building and managing training datasets without manual labeling Automatically: models, cleans, and integrates the resulting training data Applies novel, theoretically-grounded techniques Also offers data augmentation and slicing  Data programming pipeline in Snorkel Data Augmentation How do you get more data?  Augmentation as a way to expand datasets One way is introducing minor alterations For images: flips, rotations, etc  How does augmentation data help?  Adds examples that are similar to real examples Improves coverage of feature space Beware of invalid augmentations  Other advanced techniques  Semi-supervised data augmentation. e.g., UDA, semi-supervised learning with GANs Policy-based data augmentation e.g., AutoAugment  Preprocessing Different Data Types Different types of data  TRX pre-processing capabilities for multiple data types  Images Video text audio time series    Time series data Time series forecasting  predicts future events by analyzing data from the past makes predictions on data indexed by time example:  predict future temperature at a given location based on historical meteorological data    Time series dataset: weather prediction  to preprocess time series data with tensorflow transform to convert data int sequences of time steps  making data ready to train a long short-term memory recurrent neural network    Sensors and signals  Signals are sequences of data collected from real time sensors Each data point is indexed by a timestamp Sensors and signals data is thus time series data Example: classify sequences of accelerometer data recorded by the sensors on smartphones to identify the associate activity  Human activity recognition   HAR tasks require segmentation operations\n Raw inertial data from wearables fluctuate greatly over time Segmented data should be transformed for modeling Different methods of transformation:  Spectrograms normalization end encoding Multichannel Fourier transform      Reading Hand Labeling\nWeak supervision\nSnorkel\nHow do you get more data?\nAdvanced Techniques\nImages in tensorflow\nCIFAR-10\n https://www.cs.toronto.edu/~kriz/cifar.html https://www.tensorflow.org/datasets/catalog/cifar10  Weather dataset\nHuman Activity Recognition\nPapers\nLabel Propagation:\nIscen, A., Tolias, G., Avrithis, Y., \u0026amp; Chum, O. (2019). Label propagation for deep semi-supervised learning. https://arxiv.org/pdf/1904.04717.pdf\nSlide 13 active learning:\nSource: Original slides by Yale Cong\n","date":1625087619,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625087619,"objectID":"1ebe3fc9860bc13317bc00d890914ce8","permalink":"/post/mlops2/","publishdate":"2021-06-30T14:13:39-07:00","relpermalink":"/post/mlops2/","section":"post","summary":"Here is the note I took for the second course of the Machine Learning Engineering for Production (MLOps) Specialization. In this course, I learned how to accomplish data collection for ML production system, implement feature engineering, transformation, and selection with TensorFlow Extended, and establish the data lifecycle by leveraging data lineage and provenance metadata tools and follow data evolution with enterprise data schemas.","tags":["Python","Machine learning"],"title":"Notes for Machine Learning Data Lifecycle in Production (MLOps2) on Coursera/Deeplearning.ai","type":"post"},{"authors":[],"categories":[],"content":"Week 1: Steps of an ML project The ML project lifecycle MLOps (Machine learning Operations) comprises a set of tools and principles to support progress through the ML project lifcycle.\nScoping  Decide to work on speech recognition for voice search Decide on key metrics:  Acc, latency, throughput   Estimate resources and timeline  Define data  Is the data labeled consistently How much silence before/after each clip? How to perform volume normalization?  Modeling Deployment Data drift and concept drift Data drift: the input data has changed. The distribution of the variables is meaningfully different. As a result, the trained model is not relevant for this new data.\nConcept drift occurs when the patterns the model learned no longer hold.\nIn contrast to the data drift, the distributions (such as user demographics, frequency of words, etc.) might even remain the same. Instead, the relationships between the model inputs and outputs change.\nSoftware engineering issues  Realtime of Batch Cloud vs. Edge/Browser Compute resources (CPU/GPU/memory) Latency, throughput (QPS) Logging Security and privacy  Common deployment cases  New product/capability Automate/assist with manual task Replace previous ML system  Key idesa:\n Gradual ramp up with monitoring Rollback  Shadow mode  ML system shadows the human and runs in parallel. Ml system\u0026rsquo;s output not used for any decisions during this phase.  Canary deployment  Roll out to small fraction (say 5%) of traffic initially. Monitor system and ramp up traffic gradually.  Blue green deployment  Easy way to enable rollback  Degrees of automation Monitoring dashboard  Brainstorm the things that could go wrong. Brainstorm a few statistics/metrics that will detect the problem. It is ok to use many metrics initially and gradually remove the ones you find not useful.  Examples of metrics to track  Software metrics: memory, compute, latency, throughout, server load Input metrics: avg input length, avg input volume, num missing values, avg image brightness Output metrics # times return \u0026lsquo;'(null), # times user  Just as ML modeling is iterative, so is deployment Monitoring dashboard  Set thresholds for alarms Adapt metrics and thresholds over time  Model maintenance  Manual retraining Automatic retraining  Metrics to monitor  Monitor  Software metrics Input metrics Output metrics   How quickly do they change?  User data generally has slower drift. enterprise data (B2B applications) can shift fast.    Code Link : Github Repo Reading Material Week 1:  Machine Learning in Production: Why You Should Care About Data and Concept Drift Monitoring Machine Learning Models in Production A Chat with Andrew on MLOps: From Model-centric to Data-centric AI  Week 2: Select and train model Selecting and Training a Model Model development is an iterative process Challenges in model development  Doing well on training set (usually measured by average training error) Doing well on dev/test sets. Doing well on business metrics/project goals.  Performance on disproportionately important example Web search example\n Informational and transactional queries Navigational queries  Performance on key slices of the dataset  Example: ML for loan approval: makes sure not to discriminate by ethnicity, gender, location, language of other protected attributes. Example: Product recommendations from retailers: Be careful to treat fairly all major user, retailer, and product categories.  Rare classes  Skewed data distribution Accuracy in rare classes  Unfortunate conversation in many companies  I did well on the test set But this doesn\u0026rsquo;t work for my application  Establishing a baseline level of performance Unstructured and structured data  Unstructured data: Image, Audio, Text (HLP is important) Structured data: a data frame  Ways to establish a baseline  Human level performance Literature search for state-of-the-art/open source Quick-and-dirty implementation Performance of older system  Baseline helps to indicates what might be possible. In some cases (such as HLP) is also gives a sense of what is irreducible error/Bayes error.\nGetting started on modeling  Literature search to see what\u0026rsquo;s possible (courses, blogs, open-source projects). Find open-source implementations if available. A reasonable algorithm with good data will often outperform a great algorithm with no so good data.  Deployment constraints when picking a model Should you take into account deployment constraints when picking a model?\n Yes, if baseline is already established and goal is to build and deploy. No (or not necessarily), if purpose is to establish a baseline and determine what is possible and might be worth pursuing.  Sanity-check for code and algorithm  Try to overfit a small training dataset before training on a large one.  Error analysis and performance auditing Error analysis example Speech recognition example Iterative process of error analysis Useful metrics for each tag  What fraction of errors has that tag? Of all data with that tag, what fraction is misclassified? What fraction of all the data has that tag? How much room for improvement is there on data with that tag?  Prioritizing what to work on Decide on most important categories to work on based on:\n How much room for improvement there is How frequently that category appears How easy is to improve accuracy in that category How important it is to improve in that category  Adding/improving data for specific categories For categories you want to prioritize:\n Collect more data Use data augmentation to get more data Improve label accuracy/data quality  Skewed datasets Confusion matrix: Precision and Recall What happens with print(\u0026lsquo;0\u0026rsquo;)? Combining precision and recall — F1 score Multi-class metrics Performance auditing Auditing framework Check for accuracy, fairness/bias, and other problems.\n Brainstorm the ways the system might go wrong.  Performance on subsets of data (e.g., ethnicity, gender). How common are certain errors (e.g., FP, FN). Performance on rare classes.   Establish metrics to assess performance against these issues on appropriate slices of data. Get business/product owner buy-in.  Speech recognition example  Brainstorm the ways the system might go wrong.  Accuracy on different genders and ethnicities. Accuracy on different devices. Prevalence of rude mis-transcriptions.   Establish metrics to assess performance against these issues on appropriate slices of data.  Mean accuracy for different genders and major accents. Mean accuracy on different devices. Check for prevalence of offensive words in the output.    Data iteration Data-centric AI development  Model-centric view: take the data you have, and develop a model that does as well as possible on it.  Hold the data fixed and iteratively improve the code/model.   Data-centric view: the quality of the data is paramount. Use tools to improve the data quality; this will allow multiple models to do well.  Hold the code fixed and iteratively improve the data.    A useful picture of data augmentation Data augmentation   Goal:\n Create realistic examples that (i) the algorithm does poorly on, but (ii) humans (or other baseline) do well on    Checklist:\n Does it sound realistic? Is the x→ y mapping clear? (e.g. can humans recognize speech?) Is the algorithm currently doing poorly on it?    Data iteration loop Can adding data hurt performance? For unstructured data problems, if:\n The model is large (low bias). The mapping x→y is clear (e.g., given only the input x, humans can make accurate predictions).  Then, adding data rarely hurts accuracy.\nAdding features to structured data   Restaurant recommendation example:\n Vegan are frequently recommended restaurants with only meat options. Possible features to add?  Is person vegan (based on past orders)? Does restaurant have vegan options (based on menu)?      Other food delivery examples\n Only tea/coffee and only pizza What are the added features that can help make a decision? Product recommendation:  Collaborative filtering ——\u0026gt; Content based filtering (cold-start)\n  Data iteration  Error analysis can be harder if there is not good baseline (such as HLP) to compare to. Error analysis, user feedback and benchmarking to competitors can all provide inspiration for features to add.  Experiment tracking  What to track?  Algorithm/code versioning Dataset used Hyperparameters Results   Tracking tools  Text files spreadsheet Experiment tracking system   Desirable features  Information needed to replicate results Experiment results, ideally with summary metrics/analysis Perhaps also: resource monitoring, visualization, model error analysis    From big data to good data Try to ensure consistently high-quality data in all phases of the ML project lifecycly\nGood data:\n Covers important cases (good coverage of inputs x) Is defined consistently (definition of labels y is unambiguous) Has timely feedback from production data (distribution covers data drift and concept drift) Is sized appropriately  Code Link : Google Colab Reading Material Week 2:\n Establishing a baseline Error analysis Experiment tracking  Week 3: Data Definition and Baseline Define Data and Establish Baseline Data definition questions  What is the input x?  lightning? contrast? resolution? What features need to be in included?   What is the target label y?  How can we ensure labelers give consistent labels?    Major types of data problems Unstructured vs. structured data  Unstructured data  may or may not have huge collection of unlabeled examples x. Humans can label more data. Data augmentation more likely to be helpful.   Structured data  May be more difficult to obtain more data. Human labelling may not be possible (with some exceptions)    Small data vs. big data  Small data  Clean labels are critical Can manually look through dataset and fix labels Can get all the labelers to talk to each other   Big data  Emphasis data process    Why label consistency is important? Big data problems can have small data challenges too Problems with a large dataset but where there\u0026rsquo;s a long tail or rare events in the input will have small data challenges too.\n Web search Self-driving cars Product recommendation systems  Improving label consistency  Have multiple labelers label same example. When there is disagreement, have MLE, subject matter expert (SME) and/or labelers discuss definition of y to reach agreement. If labelers believe that x doesn\u0026rsquo;t contain enough information, consider changing x. Iterate until it is hard to significantly increase agreement  Have a class/label to capture uncertainty Small data vs. big data (unstructured data)  Small data  Usually small number of labelers Can ask labelers to discuss specific labels   Big data  Get to consistent definition with a small group. Then send labeling instructions to labelers. Can consider having multiple labelers label every example and using voting or consensus labels to increase accuracy.    Why measure HLP? Estimate Bayes error / irreducible error to help with error analysis and prioritization.\nOther uses of HLP  In academia, establish and beat a respectable benchmark to support publication. Business or product owner asks for 99% accuracy. HLP helps establish a more reasonable target. \u0026ldquo;Prove\u0026rdquo; the ML system is superior to humans doing the job and thus the business or product owner should adopt it. (Use with caution)  The problem with beating HLP as a \u0026lsquo;proof\u0026rsquo; or ML \u0026lsquo;superiority\u0026rsquo; Raising HLP When the ground truth label is externally defined, HLP gives an estimate for Bayes error / irreducible error.\nBut often ground truth is just anther human label.\n When the label y comes from a human label, HLP \u0026laquo; 100% may indicate ambiguous labeling instructions. Improving label consistency will raise HLP This makes it harder for ML to beat HLP. But the more consistent labels will raise ML performance, which is ultimately likely to benefit the actual application performance.  HLP on structured data Structured data problems are less likely to involve human labelers, thus HLP is less frequently used.\nSome exceptions:\n User ID merging: same person? Based on network traffic, is the computer hacked? Is the transaction fraudulent? Spam account? Bot? From GPS, what is the mode transportation - on foot, bike, car, bus?  Label and Organize Data How long should you spend obtaining data?  Get into this iteration loop as quickly as possible. Instead of asking: how long it would take to obtain m examples? ask: How much data can we obtain in k days. Exception: if you have worked on the problem before and from experience you know you need m examples.  Inventory data Brainstorm list of data sources\nOther factors: data quality, privacy, regulatory constrains\nLabeling data  Options: in-house vs. outsourced vs. crowdsourced Having MLEs label data expensive. But doing this for just a few days is usually fine Who is qualified to label?  Speech recognition - any reasonable fluent speaker Factory inspection, medical image diagnosis - SME (subject matter expert) Recommender systems - maybe impossible to label well   Don\u0026rsquo;t increase data by more than 10x at a time  Data pipeline example POC and Production phases  POC(proof-of-concept):  Goal is to decide if the application is workable and worth deploying. Focus on getting the prototype to work It\u0026rsquo;s ok if data pre-processing is manual. But take extensive notes/comments   Production phase: After project utility is established, use more sophisticated tools to make sure the data pipeline is replicable. E.g., Tensor Flow Transform, Apache Beam, Airflow, \u0026hellip;  Data pipeline example Meta-data  Examples:  Manufacturing visual inspection: time, factory, line #, camera settings, phone model, inspector ID,\u0026hellip; Speech recognition: device type, labeler ID, VAD model ID,\u0026hellip;   Useful for:  Error analysis. Spotting unexpected effects. Keeping track of data provenance.    Balanced train/dev/test/ splits in small data problems Visual inspection example: 100 examples, 30 positive (defective)\n Train/dev/test: 60%/20%/20% Random split: positive example: 21/2/7 (35%/10%/35%)→ dev set is not representative Want: 18/6/6 (30%/30%/30%) →balanced split No need to worry about this with large datasets - a random split will be representative  Scooping What is scoping? Scoping process Separating problem identification from Feasibility: Is this project technically feasible?  Use external benchmark (literature, other company, competitor)  Why use HLP to benchmark? People are very good on unstructured data tasks\nCriteria: can a human, given the same data, perform the task?\nDo we have features that are predictive?  Given past purchases, predict future purchases ✅ Given weather, predict shopping mall foot traffic ✅ Given DNA info, predict heart disease ❓ Given social media chatter, predict demand for a clothing style ❓ Given history of stock\u0026rsquo;s price, predict future price of that stock ❌  History of project Diligence on value Ethical considerations  Is this project creating net positive societal value? Is this project reasonable fair and free from bias? Have any ethical concerns been openly aired and debated?  Milestones \u0026amp; Resourcing Key specifications:\n ML metrics (accuracy, precision/recall, etc.) Software metrics (latency, throughput, etc. given compute resources) Business metrics (revenue, etc.) Resources needed (data, personnel, help from other teams) Timeline  If unsure, consider benchmarking to other projects, or building a POC (Proof of Concept) first.\nColab: https://www.coursera.org/learn/introduction-to-machine-learning-in-production/ungradedLab/hnDmK/data-labeling/lab Reading Material Week 3:\nLabel ambiguity\nhttps://arxiv.org/pdf/1706.06969.pdf\nData pipelines\nData lineage\nMLops\nOverall resources:\nKonstantinos, Katsiapis, Karmarkar, A., Altay, A., Zaks, A., Polyzotis, N., … Li, Z. (2020). Towards ML Engineering: A brief history of TensorFlow Extended (TFX). http://arxiv.org/abs/2010.02013\nPaleyes, A., Urma, R.-G., \u0026amp; Lawrence, N. D. (2020). Challenges in deploying machine learning: A survey of case studies. http://arxiv.org/abs/2011.09926\n","date":1623119494,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1623119494,"objectID":"f0fd6a5b7fe965f79c1cf21bb7acf4ae","permalink":"/post/mlops1/","publishdate":"2021-06-07T19:31:34-07:00","relpermalink":"/post/mlops1/","section":"post","summary":"Here is the note I took for the course 'Introduction to Machine learning in Production (MLOps)' at Coursera/Deeplearning.ai. This is the first course of the Machine Learning Engineering for Production (MLOps) Specialization. In this course, I learned about the key components of ML life cycle and pipeline in production settings and how to solve problems for structured, unstructured, small, and big data.","tags":["Python","Machine learning"],"title":"Notes for Introduction to Machine Learning in Production (MLOps1) on Coursera/Deeplearning.ai","type":"post"},{"authors":[],"categories":[],"content":"Background When a stimulus from the past is re-encountered, this can elicit increased neural activation relative to a novel stimulus (repetition enhancement) or decreased activation (repetition attenuation). Studies of episodic memory have consistently found that repetition enhancement occurs within parietal cortex and that these enhancement effects are related to behavioral expressions of successful episodic remembering. Repetition attenuation, in contrast, is more typically observed in regions of occipitotemporal cortex and is less consistently related to behavioral expressions of episodic memory. Separately, pattern-based fMRI studies have found that information about the content of stimuli is reflected in both parietal cortex and ventral temporal cortex, but it is less clear how or whether these content representations are integrated with repetition-related memory signals.\nMethods Dataset In this study, we utilize the Natural Scene Dataset (NSD), which is 7T fMRI study with data size around 2+ TB. In this dataset, eight participants performed a continuous recognition task spanning 30-40 fMRI scan sessions and up to 10,000 unique, naturalistic images. Vectorize memory content In the study, the stimuli subjects remembered were images from COCO dataset. Thus, to vectorized the memory content information, we can extract information from each image.\nSemantic models Since each image from COCO dataset are annotated by human workers with English, we started by analyzing the image content with two popular semantic models: Word2vec and Fast sentence embedding (fse). However, after comparing the similarity analysis based on the embedding from these two semantic models and our human raters on a small subset of the images, we were not satisfying with these two methods in terms of capturing the image content information.\nVGG16 We believe the undesirable results from the semantic models are due to the quality of the annotation: each image was annotated by five human workers, and each worked wrote one single sentence to describe the image. With this setting, the richness of the annotation is very limited so that the annotation is not representative to the image content. To solve this problem, we believe quantifying the image content directly from the visual part of the image would be a closer approximation of the memory content. After literature review, we decided that VGG16, a convolutional neural network designed for image content classification and detection, would be a good candidate for our purpose. We passed the images through VGG16 and used the output from the last fully connected layer (fc3) as the content vector of each image. The VGG16 model was trained on Imagenet, which is a different image dataset from COCO. To make sure the difference of image dataset won\u0026rsquo;t be a problem for adopting the neural network in our analysis, I visualized all the images in our experiment based on their VGG16 fc3 feature similarity with t-SNE (see figure below). As can been, the feature output from the last fully connected layer can successfully represent both local and global distance of image similarity. Although the model learned from low level visual features, it can still capture high level information of the image. Here is a post I wrote about how to extract features of VGG16 with pytorch and visualize images base on their similarity with t-SNE.\nModel prediction We calculated the difference in multivoxel fMRI activations between the first presentation (initial encoding) and second presentation (retrieval) for each stimulus and tested whether these repetition-related differences in activity patterns carried information about the visual content of the image. As demonstrate previously, to quantify the content of each image, we passed the images through VGG16, a convolutional neural network designed for image content classification and detection. We then reduced features from the output layer to 10 PCA dimensions and used ridge regression to test whether repetition-related changes in fMRI activity patterns predicted the PCA content scores. We used MSE to evaluate model performance, comparing it with 1000 permutation model results.\nConclusion We found that repetition-related differences in medial and lateral parietal cortex predicted image content significantly above chance level (1000 permutation test). Moreover, these predictions were significantly better for hits (correct recognition) compared to misses (failed recognition) indicating that the presence of content information was directly related to successful recognition. Interestingly, repetition-related differences in occipitotemporal cortex also predicted image content, but the success of these predictions were less dependent on successful behavioral recognition. Collectively, our results indicate that repetition-related enhancements which have consistently been observed in parietal cortex directly integrate information about the content of what is being remembered.\n","date":1621382428,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621382428,"objectID":"733590e4ea80e6655ecb5c3e152ee6ec","permalink":"/project/nsd/","publishdate":"2021-05-18T16:00:28-08:00","relpermalink":"/project/nsd/","section":"project","summary":"Using ridge regression, we found memory-related neural activity in parietal cortex can successfully predict the memory content (which is vectorized by the final fully connected layer's output from VGG16.)","tags":["fMRI","Big data","Python","Neural network","Natural language processing","Machine learning"],"title":"Decoding memory content from human parietal cortex: VGG16 application on memory research","type":"project"},{"authors":[],"categories":[],"content":"While working on my first grad school project, I found in our research field, the analysis of multiple testing is involved in almost every project, since we need to compute same analysis over multiple brain regions. Thus, we need to apply same basic descriptive statistics, different variants of t-tests, and multiple comparison correction to multiple groups.\nQuickly I got tedious about writing similar long pipelines of doing the multiple testing analysis, so I decided to wrap up my pipeline into functions, and combine functions into a package, and {roistats} came out! All the functions from the package can be used in combination with dplyr.\nFor the detail of what functions are included and how to use them, check out the website for this package: https://irisfee.github.io/roistats/index.html\n","date":1615064028,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615064028,"objectID":"6825fe0c5bf2ea0032d5cb62c6ba0322","permalink":"/project/roistats/","publishdate":"2021-03-06T13:53:48-07:00","relpermalink":"/project/roistats/","section":"project","summary":"The goal of this package is to apply same basic statistical tests with multiple comparison correction across multiple sub-groups, with the output being a nice arranged data.frame instead of detailed listed information.","tags":null,"title":"{roistats}: an R package for fast and easy multiple testing analysis","type":"project"},{"authors":null,"categories":[],"content":"The paper is published on Journal of Neuroscience: https://www.jneurosci.org/content/41/13/3014.full#sec-27\nBackground Given the vast number of memories that humans store, overlap between memories is inevitable. The similarity between memories could cause confusion when trying to retrieve a certain piece of memory. For example, one student in your stats class is called Mario, while another student in your algorithm class is called Wario. These two guys not only have look similar but also tend to dress in a similar style. You may accidentally call Mario, Wario. However, after several weeks of classes, you can definitely tell Mario and Wario apart because your brain develop some strategies to mange the competition in memory.\nEvidence from recent neuroimaging studies hints at the idea that memory representations are distorted as an adaptive response to interference. Namely, several studies have found that, when similar events are encoded into memory, this triggers a targeted exaggeration of differences in patterns of activity. Yet, a critical limitation of these studies is that the feature dimensions along which memories move are underspecified. That is, do changes in neural representations correspond to changes in the information content of memories?\nHere, we tested whether interference between highly similar memories triggers adaptive distortions in memory representations and corresponding behavioral expressions of memories. Our motivating theoretical perspective was that subtle differences between similar memories are prioritized and exaggerated to reduce the potential for interference.\nControlled experiment design In order to answer the question, we used color as the memory feature to probe since that color is 1. continuous and 2. can be reported by participants.\nSpecially, we used a 2-day procedure in which participants received extensive behavioral training on face-object associations on day 1 and then returned on day 2 for additional behavioral training, followed by an fMRI session, and finally a behavioral color memory test. A critical feature of our design is that we held color similarity between pairmates constant (24 degrees apart), but we included a competitive and noncompetitive condition. In the competitive condition, pairmate images corresponded to the same object category (e.g., two beanbags of slightly different colors). In the noncompetitive condition, pairmates corresponded to distinct object categories (e.g., a pillow and a ball of slightly different colors). Thus, in both conditions, the pairmates were 24 degrees apart in color space; but, for the competitive condition, color was the only feature dimension on which the pairmates differed.\nResult Behavioral performance analysis As for the result, first we found that participants exaggerated the color difference between the two similar objects for only for the competitive condition, not for the non-competitive condition. Moreover, the greater memory exaggeration was associated with lower memory interference (indicated by the better associative memory performance). See figures below.\nNeural imaging data (fMRI) analysis Image Data processing\nAfter pass the fMRI through the basic preprocessing pipeline, we smoothed the data with a 1.7 mm FWHM Gaussian kernel and high pass filtered at 0.01 Hz to increase signal-to-noise-ratio (SNR). We modeled data with “least-squares separate” method. With this method, each item was estimated in a separate GLM as a separate regressor while all remaining items were modeled together with another regressor. The six movement parameters and framewise displacement were included in each GLM as confound regressors. This resulted in t maps that were used for the multivariate pattern analysis (MVPA).\nNeural representation of color information during recall\nAs predicted, the greater relevance of color information in the competitive condition resulted in stronger representation of color information during recall, despite the fact that participants had not been explicitly oriented to color information in any way by this point of the experiment (the critical behavioral test of color memory occurred after fMRI scanning).\nNeural measures of pairmate similarity predict color memory bias\nMoreover, we found only for the competitive condition, the more dissimilar vIPS activity patterns were when recalling pairmates, the greater the color memory repulsion effect for those pairmates. A mediation analysis performed at the level of individual pairmates also revealed that the relationship between vIPS dissimilarity and associative memory accuracy was significantly mediated by signed color memory distance, consistent with the interpretation that vIPS dissimilarity reflected the degree of color memory repulsion, which in turn was associated with better associative memory accuracy (lower interference).\nConclusion Here, we show that competition between similar memories triggers biases in their neural representations and corresponding behavioral expressions. Specifically, we demonstrate that subtle, diagnostic differences between events were exaggerated in long-term memory and that this exaggeration reduced interference. Critically, these behavioral expressions of memory distortion were predicted by adaptive, feature-specific changes to memory representations in parietal cortex.\nNew #JNeurosci research from @_zhaoyufei, @AChanales \u0026amp; @KuhlLab demonstrates that in order to remember similar events, the brain exaggerates the difference between them, resulting in divergent brain activity patterns but better memory performance.https://t.co/JTFCrG4d5t pic.twitter.com/HkopLO1rkF\n\u0026mdash; SfN Journals (@SfNJournals) February 22, 2021  ","date":1613949003,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1613949003,"objectID":"bc06b4429ef3fa77c5b7b00d58adce3d","permalink":"/project/color-differentiation/","publishdate":"2021-02-21T15:10:03-08:00","relpermalink":"/project/color-differentiation/","section":"project","summary":"An fMRI study with MVPA and SEM analysis that reveal how our brains actively reduce interference caused by similarity between memories to achieve for better memory performance.","tags":["fMRI","MVPA","Python","R"],"title":"Efficient way of the brain for resolving similar memory interference","type":"project"},{"authors":[],"categories":[],"content":"In this notebook, I am going to show you  How to extract the features for a set of images at a certain layer of VGG16 pretrained model with PyTorch. How to use PCA(Principle component analysis) to reduce the feature dimension for better visualization. How to use t-SNE to visualize the image set based on their similarity of layer features (visualize the n-dimension features as 2-d distance).  Image set for example Here, I am using images from Natural Scene Dataset. The Natural Scenes Dataset (NSD) is a large-scale fMRI dataset conducted at ultra-high-field (7T) strength at the Center of Magnetic Resonance Research (CMRR) at the University of Minnesota. The dataset consists of whole-brain, high-resolution (1.8-mm isotropic, 1.6-s sampling rate) fMRI measurements of 8 healthy adult subjects while they viewed thousands of color natural scenes over the course of 30–40 scan sessions. Images used in this dataset are originally from Microsoft COCO. I am working on semantic and memory-related exploratory analysis about this dataset.\nfrom pathlib import Path import h5py from torchvision import models from PIL import Image from torchvision import transforms import numpy as np  Read in the image NSD images are square-cropped images from Microsoft Coco dataset\n# import stimuli sti_dir = Path('/projects/hulacon/shared/nsd/nsddata_stimuli/stimuli/nsd/nsd_stimuli.hdf5').as_posix() sti = h5py.File(sti_dir,'r') sti_array = sti['imgBrick']  Read in the pretrianed VGG16 model # import model pretrained_model = models.vgg16(pretrained=True).features pretrained_model.eval()  Sequential( (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): ReLU(inplace=True) (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (3): ReLU(inplace=True) (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (6): ReLU(inplace=True) (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (8): ReLU(inplace=True) (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (11): ReLU(inplace=True) (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (13): ReLU(inplace=True) (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (15): ReLU(inplace=True) (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (18): ReLU(inplace=True) (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (20): ReLU(inplace=True) (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (22): ReLU(inplace=True) (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (25): ReLU(inplace=True) (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (27): ReLU(inplace=True) (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (29): ReLU(inplace=True) (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) )  Above we can see the convolutional layer structure of VGG. The index of each layer is labeled. I will use the pooling layer 1 as the example.\nconv_layer = { 'conv1': 0, 'conv2': 2, 'conv3': 5, 'conv4': 7, 'conv5': 10, 'conv6': 12, 'conv7': 14, 'conv8': 17, 'conv9': 19, 'conv10': 21, 'conv11': 24, 'conv12': 26, 'conv13': 28} pooling_layer = { 'pool1': 4, 'pool2': 9, 'pool3': 16, 'pool4': 23, 'pool5': 30} selected_layer = pooling_layer['pool1']  selected_layer  4  Image preprocessing Here, we define the function that can normailize the input images.\n# define preprocess parameters # mini-batches of 3-channel RGB images of shape (3 x H x W) preprocess = transforms.Compose([ transforms.Resize(224), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), ]) def image_preprocess(img): \u0026quot;\u0026quot;\u0026quot; Preprocess the image and create the tensor \u0026quot;\u0026quot;\u0026quot; im = Image.fromarray(img) input_tensor = preprocess(im) # create tensor input_batch = input_tensor.unsqueeze(0)# create a mini-batch as expected by the model return input_batch  Feature extraction Here, we define the function that can extract features at a centain layer\ndef feature_extract(tensor, selected_layer): for index,layer in enumerate(pretrained_model): # print(index, layer) tensor = layer(tensor) if (index == selected_layer): return tensor  Read in and preprocess pictures We are going to use 200 pictures from the stimuli set as an example. We flatten all the feature for each image in order to calculate distance between image features/ use t-SNE\nfeatures = [] pic_number = 200 for iImage in range(pic_number): img = sti_array[iImage,:,:,:] input_batch = image_preprocess(img) current_features = np.squeeze(feature_extract(input_batch, selected_layer).data.numpy()) # print(current_features.shape) features.append(np.concatenate(current_features, axis=None))  features = np.array(features) features.shape  (200, 802816)  Since we are using the pooling layer, the feature numbers aren\u0026rsquo;t crazily large. We can skip the following steps for PCA. If you are extracting features from convolutional layers, PCA would be very helpful.\n# from sklearn.decomposition import PCA # # pca = PCA(n_components=1000) # pca.fit(features)  # pca_features = pca.transform(features)  t-SNE visualization Here, we are just using some default hyperparameters for t-SNE for a simple visualization. You can try to tune the hyperparameters if you like.\nfrom sklearn.manifold import TSNE images = sti_array[0:pic_number,:,:,:] features = np.array(features) tsne = TSNE(n_components=2, learning_rate=150, perplexity=30, angle=0.2, verbose=2).fit_transform(features) tx, ty = tsne[:,0], tsne[:,1] tx = (tx-np.min(tx)) / (np.max(tx) - np.min(tx)) ty = (ty-np.min(ty)) / (np.max(ty) - np.min(ty))  [t-SNE] Computing 91 nearest neighbors... [t-SNE] Indexed 200 samples in 4.441s... [t-SNE] Computed neighbors for 200 samples in 45.717s... [t-SNE] Computed conditional probabilities for sample 200 / 200 [t-SNE] Mean sigma: 321.907110 [t-SNE] Computed conditional probabilities in 0.021s [t-SNE] Iteration 50: error = 110.1199646, gradient norm = 0.3914785 (50 iterations in 0.065s) [t-SNE] Iteration 100: error = 119.6677475, gradient norm = 0.2513522 (50 iterations in 0.065s) [t-SNE] Iteration 150: error = 120.5060120, gradient norm = 0.2420261 (50 iterations in 0.063s) [t-SNE] Iteration 200: error = 117.5590820, gradient norm = 0.4199304 (50 iterations in 0.063s) [t-SNE] Iteration 250: error = 122.9965286, gradient norm = 0.2279717 (50 iterations in 0.060s) [t-SNE] KL divergence after 250 iterations with early exaggeration: 122.996529 [t-SNE] Iteration 300: error = 2.4189911, gradient norm = 0.0285375 (50 iterations in 0.060s) [t-SNE] Iteration 350: error = 1.8055801, gradient norm = 0.0019180 (50 iterations in 0.062s) [t-SNE] Iteration 400: error = 1.6958097, gradient norm = 0.0008569 (50 iterations in 0.062s) [t-SNE] Iteration 450: error = 1.6566454, gradient norm = 0.0006347 (50 iterations in 0.061s) [t-SNE] Iteration 500: error = 1.6307240, gradient norm = 0.0004043 (50 iterations in 0.061s) [t-SNE] Iteration 550: error = 1.6122439, gradient norm = 0.0003583 (50 iterations in 0.060s) [t-SNE] Iteration 600: error = 1.5946932, gradient norm = 0.0002276 (50 iterations in 0.059s) [t-SNE] Iteration 650: error = 1.5851456, gradient norm = 0.0002688 (50 iterations in 0.057s) [t-SNE] Iteration 700: error = 1.5735952, gradient norm = 0.0011064 (50 iterations in 0.057s) [t-SNE] Iteration 750: error = 1.5616177, gradient norm = 0.0003782 (50 iterations in 0.057s) [t-SNE] Iteration 800: error = 1.5549071, gradient norm = 0.0001757 (50 iterations in 0.058s) [t-SNE] Iteration 850: error = 1.5460689, gradient norm = 0.0002423 (50 iterations in 0.057s) [t-SNE] Iteration 900: error = 1.5415170, gradient norm = 0.0001737 (50 iterations in 0.057s) [t-SNE] Iteration 950: error = 1.5383173, gradient norm = 0.0000928 (50 iterations in 0.057s) [t-SNE] Iteration 1000: error = 1.5367311, gradient norm = 0.0000665 (50 iterations in 0.059s) [t-SNE] KL divergence after 1000 iterations: 1.536731  from matplotlib.pyplot import imshow import matplotlib width = 4000 height = 3000 max_dim = 100 full_image = Image.new('RGBA', (width, height)) for img, x, y in zip(images, tx, ty): tile = Image.fromarray(img) rs = max(1, tile.width/max_dim, tile.height/max_dim) tile = tile.resize((int(tile.width/rs), int(tile.height/rs)), Image.ANTIALIAS) full_image.paste(tile, (int((width-max_dim)*x), int((height-max_dim)*y)), mask=tile.convert('RGBA')) matplotlib.pyplot.figure(figsize = (16,12)) imshow(full_image)  \u0026lt;matplotlib.image.AxesImage at 0x2aab23e3dcf8\u0026gt;  You can see clear color and shape clusters in the visualization. This makes sense since the pooling layer 1 is at a very early stage, which caputres relatively low level features of the images.\nIn below, the visulation based on pooling layer 5 is presented. You can clearly see some semantic category clusters, like bears and bananas.\nImage(filename='samples/pool5_600pics_try2.png')  Reference  https://github.com/utkuozbulak/pytorch-cnn-visualizations https://nextjournal.com/ml4a/image-t-sne  ","date":1605586895,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605586895,"objectID":"90e6aeab1c9de20df6da1464f0811011","permalink":"/post/vgg-viusalization/","publishdate":"2020-11-16T20:21:35-08:00","relpermalink":"/post/vgg-viusalization/","section":"post","summary":"In this notebook, I am going to show you  How to extract the features for a set of images at a certain layer of VGG16 pretrained model with PyTorch. How to use PCA(Principle component analysis) to reduce the feature dimension for better visualization.","tags":["Python","Neural network"],"title":"Visualize image set based on VGG16 Convolutional layer features","type":"post"},{"authors":[],"categories":[],"content":"Although the theory basis of my major, cognitive neuroscience, is based on psychology and biology, the skills I need to tackle with the research work of this field are most data science related. Since programming languages and data related techniques are developing with dramatically speed, staying tuned and keeping studying is a must.\nHere I want to list some books/course videos that I found super helpful along my learning path.\nPython  Think Python  I learned Python from beginning with this book.   Fluent Python  I learned many advanced skills in python from this book. Python has so many fancy functions/tricks that can be easily missed. This book help improving your codes in a more elegant and efficient way.   Python Cookbook  A book with many random skills and tricks.   Python Data Science Handbook  Learned Numpy, Pandas, Scikit-learn with this book.    R  R for Data Science  Everything you need to know about tidyverse is here.   Advanced R  Programming skills with R.   R Graphics Cookbook  Fantastic book for ggplot2 lovers.   R Packages  Built my first R package with this awesome book.   blogdown: Creating Websites with R Markdown  Interested in building a website like this one you are looking at? Check out this book. I also found Bookdown and Pagedown are so helpful.    Machine learning  CS229: Machine Learning  This machine learning is provided by Andrew Ng from Stanford. Course videos can be found via Youtube. Very comprehensive introduction to the basic knowledge of machine learning.   CS231n: Convolutional Neural Networks for Visual Recognition  As the course title implicates, this course is focused on how to apply CNN. In general it is quite straight forward if you have a solid knowledge base from CS229. Course videos can also be found via Youtube.   deeplearning.ai  Andrew Ng also provides a series of advance deep learning course via Coursera.   An Introduction to Statistical Learning  I read this book while taking the machine learning course for my Data Science Specialization at the University of Oregon. Very detailed and clear explanation for both the stats and coding of statistical learning.   The Elements of Statistical Learning: Data Mining, Inference, and Prediction  More advanced comparing with the previous one.    Misc  Intro to CSS and HTML A practical video tutorial for Illustrator Adobe Illustrator Tutorials Pro Git something about version control Unix and Linux Visual QuickStart Guide learning a bit unix will even change your experience with your pc. Mumford Brain Stats Stats knowledge in neuroscience area.  ","date":1601703053,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601703053,"objectID":"a0e95c9b123c47a052cfaf0de556d7da","permalink":"/post/ref-data-science/","publishdate":"2020-10-02T21:30:53-08:00","relpermalink":"/post/ref-data-science/","section":"post","summary":"Although the theory basis of my major, cognitive neuroscience, is based on psychology and biology, the skills I need to tackle with the research work of this field are most data science related.","tags":["Python","R","Machine learning","Neural network"],"title":"Books/video courses recommendation for data science related coding/machine learning/stats","type":"post"},{"authors":["Yufei Zhao"],"categories":null,"content":" Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including code, math, and images.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554595200,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"077e1e01fd8590c86aff39607410dbcb","permalink":"/project_landing/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/project_landing/","section":"","summary":"Hello!","tags":null,"title":"Projects","type":"widget_page"},{"authors":["Yufei Zhao","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including code, math, and images.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441065600,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication"},{"authors":["Yufei Zhao","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including code, math, and images.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example conference paper","type":"publication"},{"authors":["Yufei Zhao","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including code, math, and images.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"ff6a19061a984819d30c916886db56ef","permalink":"/publication/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/example/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"An example conference paper","type":"publication"},{"authors":null,"categories":null,"content":" .article-container { max-width: 80%; padding: 0 20px 0 20px; margin: 0 auto 0 auto; }  As an old Chinese saying goes, \u0026ldquo;Life is about reading ten thousands of books and traveling ten thousands of miles.\u0026rdquo; (读万卷书 行万里路). Besides reading, in my spare time I love traveling around the world. So far I have been to Japan, Thailand, Taiwan, France, Portugal, Spain, and of course, many cities in main-land China and the U.S., the two countries I have been spending most of my time with my beloved family and friends.                      \n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"665288c8761d48eb3366c37954243edc","permalink":"/gallery/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/gallery/","section":"","summary":".article-container { max-width: 80%; padding: 0 20px 0 20px; margin: 0 auto 0 auto; } As an old Chinese saying goes, \u0026ldquo;Life is about reading ten thousands of books and","tags":null,"title":"Gallery","type":"page"}]